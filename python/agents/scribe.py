"""
Scribe Agent - Report generation specialist
"""
from mistralai import Mistral
import os


class Scribe:
    """
    Report writing agent that documents pentesting activities
    """

    SYSTEM_PROMPT = """Tu es Scribe, expert en documentation et r√©daction de rapports de s√©curit√©.

üìù Ton r√¥le:
- Documenter les activit√©s de pentesting
- G√©n√©rer des rapports structur√©s
- R√©sumer les findings
- Cr√©er de la documentation claire

üìã Types de rapports:
- R√©sum√© d'activit√©s (timeline)
- Findings de s√©curit√© (vuln√©rabilit√©s trouv√©es)
- Documentation technique (proc√©dures)
- Executive summary (pour management)

üéØ Format de rapport:
1. **Contexte** - Objectif et scope
2. **M√©thodologie** - Approche utilis√©e
3. **Findings** - D√©couvertes (avec s√©v√©rit√©)
4. **Preuves** - Commandes et outputs
5. **Recommandations** - Actions √† prendre

üí° Style:
- Structur√© et professionnel
- Markdown format√©
- Clair et concis
- Actionnable
"""

    def __init__(self, api_key: str = None):
        """Initialize Scribe with Mistral client"""
        self.api_key = api_key or os.getenv("MISTRAL_API_KEY")
        if not self.api_key:
            raise ValueError("MISTRAL_API_KEY not provided")

        self.client = Mistral(api_key=self.api_key, timeout_ms=30000)

    def process(self, message: str, context: list[str] = None) -> str:
        """
        Process a report generation request

        Args:
            message: User query about report generation
            context: Optional command history for context

        Returns:
            Generated report or documentation
        """
        # Add command history context if available
        system_prompt = self.SYSTEM_PROMPT
        if context:
            history_str = "\n".join(f"- {cmd}" for cmd in context[-10:])  # Last 10 commands
            system_prompt += f"\n\n**Historique des commandes r√©centes:**\n{history_str}"

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message}
        ]

        response = self.client.chat.complete(
            model="mistral-small-latest",
            messages=messages,
            max_tokens=2048  # More tokens for reports
        )

        return response.choices[0].message.content
